{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 softmax回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4.1 多分类问题\n",
    "# 如果类别间有一些自然顺序， 比如说我们试图预测{婴儿，儿童，青少年，青年人，中年人，老年人}\n",
    "# 那么将这个问题转变为回归问题，并且保留这种格式是有意义的\n",
    "# 但是一般的分类问题并不与类别之间的自然顺序有关\n",
    "# 幸运的是，统计学家很早以前就发明了一种表示分类数据的简单方法：独热编码（one-hot encoding）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4.2/3.4.3 网络架构和参数开销\n",
    "# 与线性回归一样，softmax回归也是一个单层神经网络（o = XW + b），softmax回归的输出层也是全连接层\n",
    "# d输入q输出 n*d * d*q + 1*q，广播机制(分别取两者最大的维度) n*q + 1*q=>n*q = n*q\n",
    "# 对于任何具有d个输入和q个输出的全连接层，参数开销为O(dq),幸运的是，将d个输入转换为q个输出的成本可以减少到O(dq/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4.4 softmax运算\n",
    "# softmax函数能够将未规范化的预测变换为非负数并且总和为1，同时让模型保持可导的性质\n",
    "# 为了完成这一目标，我们首先对每个未规范化的预测求幂，这样可以确保输出非负\n",
    "# 为了确保最终输出的概率值总和为1，我们再让每个求幂后的结果除以它们的总和\n",
    "# 尽管softmax是一个非线性函数，但softmax回归的输出仍然由输入特征的仿射变换决定。因此，softmax回归是一个线性模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4.5 小批量样本的矢量化\n",
    "# 为了提高计算效率并且充分利用GPU，我们通常会对小批量样本的数据执行矢量计算\n",
    "# 模型O = WX + B  Y = softmax(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4.6 损失函数（由最大似然推导出来）\n",
    "# 它是所有标签分布的预期损失值。 此损失称为交叉熵损失（cross-entropy loss），它是分类问题最常用的损失之一\n",
    "# 通过介绍信息论基础来理解交叉熵损失\n",
    "\n",
    "# softmax导数是我们softmax模型分配的概率与实际发生的情况（由独热标签向量表示）之间的差异\n",
    "# 当损失函数是均方损失（求导后变成一次项）时,负梯度刚好是残差,残差只是特例\n",
    "# 从这个意义上讲，这与我们在回归中看到的非常相似，其中梯度是观测值和估计值之间的差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4.7 信息论基础\n",
    "# 可以把交叉熵想象为“主观概率为Q的观察者在看到根据概率P生成的数据时的预期惊异”\n",
    "# 当P=Q时，交叉熵达到最低。 在这种情况下，从P到Q的交叉熵是H(P,P)=H(P)\n",
    "# y=y估计时，交叉熵最低，此时H（y,y估计）=H（y）,这个交叉熵的式子和softmax损失函数一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4.8 模型评估和预测\n",
    "# 将使用精度（accuracy）来评估模型的性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 小结\n",
    "# softmax运算获取一个向量并将其映射为概率\n",
    "# softmax回归适用于分类问题，它使用了softmax运算中输出类别的概率分布\n",
    "# 交叉熵是一个衡量两个概率分布之间差异的很好的度量，它测量给定模型编码数据所需的比特数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 图像分类数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST数据集 (LeCun et al., 1998) 是图像分类中广泛使用的数据集之一，但作为基准数据集过于简单\n",
    "# 将使用类似但更复杂的Fashion-MNIST数据集 (Xiao et al., 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from d2l import torch as d2l\n",
    "\n",
    "d2l.use_svg_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5.1 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式,并除以255使得所有像素的数值均在0～1之间\n",
    "# 流行的图像处理软件通常用8位表示一个像素，这样总共有256个灰度等级(像素值在0~255 间)，每个等级代表不同的亮度\n",
    "trans = transforms.ToTensor()\n",
    "# train下载训练集，transform数据预处理，download如果地址内无则下载\n",
    "mnist_train = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=True, transform=trans, download=True)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=False, transform=trans, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist_train), len(mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, torch.Size([1, 28, 28]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每个输入图像的高度和宽度均为28像素。 数据集由灰度图像组成，其通道数为1。\n",
    "# 将高度，宽度记为（h，w）\n",
    "type(mnist_train[0]), mnist_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 标签 一个元组一个样本\n",
    "mnist_train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion_mnist_labels(labels): #@save\n",
    "    '''返回数据集的文本标签'''\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat', \n",
    "                  'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化样本\n",
    "# 使用plt.subplots函数时，可以直接在该函数内部设置子图纸信息\n",
    "# 该函数返回两个变量，一个是Figure实例fig，另一个 AxesSubplot实例axes 。fig代表整个图像，ax代表坐标轴和画的子图，\n",
    "# 通过下标获取需要的子区域，后续我们需要对子图操作时，直接ax[i].imshow(img[i])就行\n",
    "\n",
    "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5): #@save\n",
    "    '''绘制图像列表'''\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    fig, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    # axes.flatten()，其中flatten()是一种numpy数组方法–这将返回我们数组(列)的展平版本。\n",
    "    axes = axes.flatten()\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        if torch.is_tensor(img):\n",
    "            # 图片张量\n",
    "            # ax.imshow的行为是能在区域ax绘制图像，其可以接受list或者numpy.ndarray类型输入的像素点，并绘制图片\n",
    "            ax.imshow(img.numpy())\n",
    "        else:\n",
    "            # PIL格式\n",
    "            ax.imshow(img)\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "    return axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"516.6pt\" height=\"191.980982pt\" viewBox=\"0 0 516.6 191.980982\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-03-16T19:00:22.128904</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 191.980982 \n",
       "L 516.6 191.980982 \n",
       "L 516.6 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 7.2 94.060982 \n",
       "L 78.942857 94.060982 \n",
       "L 78.942857 22.318125 \n",
       "L 7.2 22.318125 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p16b28cdef4)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAYAAABw4pVUAAAJEklEQVR4nO1dXWwcVxW+MzuzP7Z3vbEdr+PaiePGIUlJ0kCdtIUmkKZJiYoCSviRIqQ+IIEQCCH+JCgSPAYJ8UJQEaU8paqgUimgthRiJSIRIRFOQxpTJ43jhMZNsv7feNe7MzvL2z33u8YLVFF9Is73dM5+45lZn73nnDn33DvOLudATQnYwF3qGxAgxCDMIAZhBjEIM4hBmEEMwgzee3ERp38j6KWOlJYTE2XgCquIy1yeA84th1qOzv3jTt4iG8gIYQYxCDOIQZjBU24MP4mq/9Ufzu3fBvq275whOX0ZuHXxU6D7KtJy0omAa3QdLc/XsKpj/npOlLqBq1q/rYGp9VoOasjdLGboXmKLf9+o5oBeCn3QZ0pJLcdcvNf5Y21abh0KgEu8fEYtBhkhzCAGYQanXrV35uCDoPd+aVjLW7NXgBucXanla4UW4III7e675KYa/ApwyRgN77jlTlxFtxopdCeNMTxPo0fpdMabBy4dI921XKaJmMJ/zemZnkWPTXuYvoeGm3yoGV34s1ce1nLz3reAkxHCDGIQZhCDMMOCGDJy6CEtf2/fr+Hg49PrtPz2XBa42UpCy8sbsOTR1TANeotPfLNXBC7pUHlkppoCrsGlOFG1YsiNcjPopSiu5SDC1L5s6KkYpqSlKqW2Wb8EXCFMgj5qxMqxSbx+UwPFqWwKY9jjHRe0fORne4CTEcIMYhBm8KIdW+CDT+0+qeUXbj4AXC5Z0PITHeeBGy52aHmslAFuNsChbrqQ6/NZ4NoTdI2ViQng0i65kLiDKXGnPw36ffExLV8LlwF3I6RrDhU78TyJGS2fn0WuGMZBdx3y9m3Nt4FrTpCb6m+5iuepknsvtS9ejRAwgBiEGcQgzOAVuhPwgekXd7a9Cdx4kNby6wWstnalprTcm8oDtyZxA3TTh7+avw84swQy7qaBGw4oTvWlbgG3p2kI9B/d3KXlT7YMAvfxxotafiSFpYuhCl1jVWIcuOlqA+jliFLk1Qm8n6BGk7ExheWZDo/i1B/PPQKcjBBmEIMwgxiEGbxiDm3yROZ1LT83ieX37uSklje1XAOuNYZ5uIm0i6WDHSl6vmh0sWx9zCjP5PwZ4LridP2PNKDvf/JrXwc9TFJp5UQPPmuFjRQnM5vxWecrawa0nHSwrGLraaOsb5fqY8axMavEb5Z9Mufx+jJCmEEMwgzOY/5nYaxtPkPV1kfTF+DgYo1S5PkIJ/zHAixPmEi4ONRvBZlFjkSsTWK63J8kN3nw+98AbvJRdIuXd/5Sy0dLWO3Nh3T934yjOxu8Run8gz04K7oxfR30mZDSYHMWUilMg7MuVrTna/S/O9y3FjgZIcwgBmEGMQgzLJgxLH+sX8vt3x2Bg+/PvK3lDSn0p2ZMSVoxY6h0D+hFYzZvRXwaONMv2+nirQqVUl65sgG4o1ufBv2psce1vDI1Cdz7U/Q99jfNqsXwfAHjYm8cyyMjlXYt2zHUTNl7fCwl9RkzkZ/r/hBwMkKYQQzCDHUb5erBW9EBerA6p+XJ9VgVLXZgQ8L9e2ltx5O5E8Dlq0bfrdHwoJRSBaPpocOaIRyYQRfWZDSuNcewWeEDqVEtT0d4r50eVa2//dYB4HINBdCfWfWyloMautfhgB4R0i428f25uEbLL25YDpyMEGYQgzCDGIQZFsQQx6OZrloYLviDO43Svq2g//MT1E1ycMtp4LY30Qzm6eK9wNlxYrlH6axZqlBKqbEKpah2it7iUdU6G8OSR9VaZzJnpO/FCGdeO4y09wFrxnT36S9qufvAG8DJCGEGMQgzLFgWDW7KwXTV8WjoOzHLli7p0TxOOtVbJpd6Cd3S2pdIPqOwSvvpUUo7tzSMAncjyILuG4109hqQrjhNCtkuKzLc0q0Qq9L2JNw9PqXIl8r4GGA2RHR5TcClf4vNGyZkhDCDGIQZxCDMUH9rDWtZci2oGPKduQHHxwZm8xo2vvqFL2v5x08fBs5XGKfMZuxKDWNRT2Jay3lrDcpgabWW01YqbcNs3vCt5m8zRT400QdcuRljswkZIcwgBmEGMQgzvCfbM9WDHTPcJC3uieaxk2N8I8WbNmtt4MUAy+hms3NgxZBjBdp243YVSx4Pp6kBz26uLljxxmx4s59ndqZokc6OI98ELr2bmrgrl/qBkxHCDGIQZlhyl2WXZ+pVmLt/QTONA5/vAS7mYIqeD6k8YVdt3zGWUF+YwJLH3uzftTxSbgeuMz4Fupla200OgxXaDWj3LlyfYvZIvxZsB05GCDOIQZhBDMIMSx9D7PJMnRhSnSIfbm7zoZRSn2n7K+hmqmunq+a6jpYUxpc3yyu07Lt4L5MhltHN83b72Iw3XW3U8rdyR4E7PPFhLXtH/wacjBBmEIMww9K7rHeJfBndh93IUDGe1Dt9TFffl6BtN1pbceeifJXS5YXnxCd+M+2118uYy9+QUerkzV4tNyrsn5YRwgxiEGYQgzDD0scQZ/HZswUwUuS+JlyrYXeEmLq9ZHmuRlXj0aBNLQaz/KIUVpCVUuqZS7S76O0R3FHODel7PfbRs8D9oI9aa36o8EUFMkKYQQzCDEvvsmp1lqfUcWenDmFP8LKn8Il7fZJS20KEO9pVaot/7Z8M79DynO2GKtb9GGothxNtYUC/9VPP4tLrc/topzpnv6wPYQ0xCDOIQZjhXa8x5IYrz28C/Vfbfq7l3xc2A3c8T41r1wes95BsonTZ97H5LTqLMaX1DeIzZ98Bbnw7LQXPfxD/xTnjdSrL/oQb9csIYQYxCDOIQZhh6Z9D/gfUa6KLn8Vy/AvraFfuk/le4K5epE6T2r34/OBdpZm+VT/F7UPCUdyuCjhLz47SVlKtv7O2rqpS7KnO4tYeMkKYQQzCDHeVy6rbRPeHadCP9NB7UNwS/u66jtOaQ89aAuK/9hct/8dF4UZpx4lZrx906Jpmc8aCU3hoAhkhzCAGYQYxCDPcXaUTsxxfr2yvlIq10vuhpvbgzp+Z507Zh//ba5jr8pWqv/6xLurNitZ5vayAAcQgzHB3uaz/A8gIYQYxCDOIQZhBDMIMYhBmEIMwgxiEGcQgzCAGYQYxCDP8CxNWoTZp4eT8AAAAAElFTkSuQmCC\" id=\"image8f1baf74da\" transform=\"scale(1 -1) translate(0 -72)\" x=\"7.2\" y=\"-22.060982\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 7.2 94.060982 \n",
       "L 7.2 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 78.942857 94.060982 \n",
       "L 78.942857 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 7.2 94.060982 \n",
       "L 78.942857 94.060982 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 7.2 22.318125 \n",
       "L 78.942857 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_1\">\n",
       "    <!-- ankle boot -->\n",
       "    <g transform=\"translate(11.348304 16.318125) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6b\" d=\"M 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 1991 \n",
       "L 2875 3500 \n",
       "L 3609 3500 \n",
       "L 1753 1863 \n",
       "L 3688 0 \n",
       "L 2938 0 \n",
       "L 1159 1709 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "M 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2969 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-61\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"61.279297\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6b\" x=\"124.658203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"182.568359\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"210.351562\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"271.875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-62\" x=\"303.662109\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"367.138672\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"428.320312\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"489.501953\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_2\">\n",
       "   <g id=\"patch_7\">\n",
       "    <path d=\"M 93.291429 94.060982 \n",
       "L 165.034286 94.060982 \n",
       "L 165.034286 22.318125 \n",
       "L 93.291429 22.318125 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p20099da8f2)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"imagef93060278e\" transform=\"scale(1 -1) translate(0 -72)\" x=\"93.291429\" y=\"-22.060982\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_8\">\n",
       "    <path d=\"M 93.291429 94.060982 \n",
       "L 93.291429 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_9\">\n",
       "    <path d=\"M 165.034286 94.060982 \n",
       "L 165.034286 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_10\">\n",
       "    <path d=\"M 93.291429 94.060982 \n",
       "L 165.034286 94.060982 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_11\">\n",
       "    <path d=\"M 93.291429 22.318125 \n",
       "L 165.034286 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_2\">\n",
       "    <!-- t-shirt -->\n",
       "    <g transform=\"translate(111.232232 16.318125) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-2d\" d=\"M 313 2009 \n",
       "L 1997 2009 \n",
       "L 1997 1497 \n",
       "L 313 1497 \n",
       "L 313 2009 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2d\" x=\"39.208984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"75.292969\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-68\" x=\"127.392578\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"190.771484\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"218.554688\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"259.667969\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_3\">\n",
       "   <g id=\"patch_12\">\n",
       "    <path d=\"M 179.382857 94.060982 \n",
       "L 251.125714 94.060982 \n",
       "L 251.125714 22.318125 \n",
       "L 179.382857 22.318125 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#pd7a319506f)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAYAAABw4pVUAAAFTElEQVR4nO2dv28cRRTHd+9HfDlfHJ2TmCCIjBRRBIIgVEgIpcA9BaGkgAZRUVDR8U/QgIQiWroIUdEjpUiRAhJREHACAdmKdfGd7273dimQZt57qxtsc7fzlfz9VG/11jt7fvt+zOzMbLqV3iiTuklTL5eHb7717EUn55sbSjfpr+gmxGVPbw+Urnzw0MnFcHi4+0ySI93rcWksvQVyJGgQMGgQMFpRWhWxuLG6qlR777zi5IPz+nnJxKmleZQas0Bzr59Tx+nMH/ceFUq3fusnJ88GOvfUAT0EDBoEjDRG2dtcW3Py7x9f1TckIkjrIHARHWmSRq5/Rhr4VUXTy+PzurSV7W9+eV/pZju7gRtaDPQQMGgQMGgQMKKUvU/fvuLk1OSClT0f/GWs//dkIZoytzTnyhTSyOffS/exTjZZzzcyfu0FpWv/wBxy4qBBwIgSsvKODwuNTOtKEZZs71vqbIhKAmXurG1LW3+y7fG3970u7+lG2vObWBj0EDBoEDBoEDCi5JDe9tjJo2e6SqfKYPvCTj4+RxjwkTmjojOqQvxHRhd0Djl9+CaPDT0EDBoEjCghqzkR9awJSzJk2F78oghdtxAl8vq98fwTlwQ9BAwaBAwaBIwoOSSdZAGlF+2wxjIobQ4T4yOtpxN97vJvhx6CBg0CBg0CRpwckol+iAnM8k1gZYhd8j8CetHyiSM1E6hlDrEzW+qAHgIGDQJG9LLXDmPI0ddKVFpC3Vk2Td0r31iOdNkbmD68MOghYNAgYNAgYERfH1KZ4CZDui2JRb6pDKuYVKCvaWadyPYrryWFvPtk/kWXBD0EDBoEjDghK19AARkIUZVTTW9chTBbdstbmwZGpZcEPQQMGgQMGgSM6GVvpbSVqlCesMMoR8gpur35FypndQyWaOghYNAgYEQJWeVw5A9sRznQUw9NeqgscQudKy5se/HyfooDTpQ78dAgYNAgYMTJIfn8dcrHnRwXHP0NvGm0a0fUG8SCZe+JhwYBgwYBI86sE1H72/5DHci+R2tc/6asIeghYNAgYMQJWV2/wHim9z/WW22Eookd3bXnimM7GU+WyHb7juna/A06g5suLwh6CBg0CBg0CBhxtmd6/JeT09llrQwOc4jTQmtHDHZYRb4lzDta1xr65FRHzrDQQ8CgQcCIM8lBENrmwpaklU0xA9cJjRrLTTHl7nZJkiSd3bg9d3oIGDQIGDQIGHA5JO/6mC43VU4S/UkouxNccFJdQBccuokAPQQMGgSM+CHLzHdIZWkbWNJWKZdtSRwop2V4s9cJfTqpDughYNAgYNAgYETPIaf2daLIxGFl6ETI/7UZf+gbVKFc1Kx/frWCHgIGDQIGDQJG9BxSmeyc+mekaM5PBJ09HfztdwyzbkPIge0zjMpep27oIWDQIGBED1lyQ0pLd0fXvTK8DS7pW7efUF174EPamYd6fGZ0wf9tZZT4mMurFwU9BAwaBAwaBIzoOUR+6jRJkqT7t4/9g019e1sf/ujkl7uPlG69ua+Ofx4/5+Sb995Quo1v/GTvSd/8CyIvF6GHgEGDgBE9ZDWmOkbkKz6EXf/gttK9dea+lzs7Stdv6s/vXW7fdfLVa9tK92n5npPPfav/btqL+4zSQ8CgQcCgQcCI8x3Dft/J07O67H3/k++d/CTXa/xu/vmmk7/I9Ay3YXZKHV9cHTj5bFu/Bvz81e+c/NngXaVbv80cQgQ0CBjpVnojat+0tXlJHf/y0fNOfvGrP5Qu//W3hbRZXL/m5N2X9Jq2ja/vOLmc6O+H1AE9BAwaBAwaBIx/ALLsUkHQHoydAAAAAElFTkSuQmCC\" id=\"image8776eb8eb0\" transform=\"scale(1 -1) translate(0 -72)\" x=\"179.382857\" y=\"-22.060982\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_13\">\n",
       "    <path d=\"M 179.382857 94.060982 \n",
       "L 179.382857 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_14\">\n",
       "    <path d=\"M 251.125714 94.060982 \n",
       "L 251.125714 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_15\">\n",
       "    <path d=\"M 179.382857 94.060982 \n",
       "L 251.125714 94.060982 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_16\">\n",
       "    <path d=\"M 179.382857 22.318125 \n",
       "L 251.125714 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_3\">\n",
       "    <!-- t-shirt -->\n",
       "    <g transform=\"translate(197.323661 16.318125) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2d\" x=\"39.208984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"75.292969\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-68\" x=\"127.392578\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"190.771484\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"218.554688\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"259.667969\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_4\">\n",
       "   <g id=\"patch_17\">\n",
       "    <path d=\"M 265.474286 94.060982 \n",
       "L 337.217143 94.060982 \n",
       "L 337.217143 22.318125 \n",
       "L 265.474286 22.318125 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p5b16338dae)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"imagea08a436e19\" transform=\"scale(1 -1) translate(0 -72)\" x=\"265.474286\" y=\"-22.060982\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_18\">\n",
       "    <path d=\"M 265.474286 94.060982 \n",
       "L 265.474286 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_19\">\n",
       "    <path d=\"M 337.217143 94.060982 \n",
       "L 337.217143 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_20\">\n",
       "    <path d=\"M 265.474286 94.060982 \n",
       "L 337.217143 94.060982 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_21\">\n",
       "    <path d=\"M 265.474286 22.318125 \n",
       "L 337.217143 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_4\">\n",
       "    <!-- dress -->\n",
       "    <g transform=\"translate(285.261964 16.318125) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
       "L 2906 4863 \n",
       "L 3481 4863 \n",
       "L 3481 0 \n",
       "L 2906 0 \n",
       "L 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "z\n",
       "M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-64\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"63.476562\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"102.339844\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"163.863281\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"215.962891\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_5\">\n",
       "   <g id=\"patch_22\">\n",
       "    <path d=\"M 351.565714 94.060982 \n",
       "L 423.308571 94.060982 \n",
       "L 423.308571 22.318125 \n",
       "L 351.565714 22.318125 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#pbb2dee9e5b)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image04a273782a\" transform=\"scale(1 -1) translate(0 -72)\" x=\"351.565714\" y=\"-22.060982\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_23\">\n",
       "    <path d=\"M 351.565714 94.060982 \n",
       "L 351.565714 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_24\">\n",
       "    <path d=\"M 423.308571 94.060982 \n",
       "L 423.308571 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_25\">\n",
       "    <path d=\"M 351.565714 94.060982 \n",
       "L 423.308571 94.060982 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_26\">\n",
       "    <path d=\"M 351.565714 22.318125 \n",
       "L 423.308571 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_5\">\n",
       "    <!-- t-shirt -->\n",
       "    <g transform=\"translate(369.506518 16.318125) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2d\" x=\"39.208984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"75.292969\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-68\" x=\"127.392578\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"190.771484\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"218.554688\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"259.667969\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_6\">\n",
       "   <g id=\"patch_27\">\n",
       "    <path d=\"M 437.657143 94.060982 \n",
       "L 509.4 94.060982 \n",
       "L 509.4 22.318125 \n",
       "L 437.657143 22.318125 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#pbc00dfce37)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image10079008d0\" transform=\"scale(1 -1) translate(0 -72)\" x=\"437.657143\" y=\"-22.060982\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_28\">\n",
       "    <path d=\"M 437.657143 94.060982 \n",
       "L 437.657143 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_29\">\n",
       "    <path d=\"M 509.4 94.060982 \n",
       "L 509.4 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_30\">\n",
       "    <path d=\"M 437.657143 94.060982 \n",
       "L 509.4 94.060982 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_31\">\n",
       "    <path d=\"M 437.657143 22.318125 \n",
       "L 509.4 22.318125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_6\">\n",
       "    <!-- pullover -->\n",
       "    <g transform=\"translate(449.202321 16.318125) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-75\" d=\"M 544 1381 \n",
       "L 544 3500 \n",
       "L 1119 3500 \n",
       "L 1119 1403 \n",
       "Q 1119 906 1312 657 \n",
       "Q 1506 409 1894 409 \n",
       "Q 2359 409 2629 706 \n",
       "Q 2900 1003 2900 1516 \n",
       "L 2900 3500 \n",
       "L 3475 3500 \n",
       "L 3475 0 \n",
       "L 2900 0 \n",
       "L 2900 538 \n",
       "Q 2691 219 2414 64 \n",
       "Q 2138 -91 1772 -91 \n",
       "Q 1169 -91 856 284 \n",
       "Q 544 659 544 1381 \n",
       "z\n",
       "M 1991 3584 \n",
       "L 1991 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 563 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2284 0 \n",
       "L 1503 0 \n",
       "L 191 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"63.476562\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"126.855469\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"154.638672\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"182.421875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-76\" x=\"243.603516\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"302.783203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"364.306641\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_7\">\n",
       "   <g id=\"patch_32\">\n",
       "    <path d=\"M 7.2 184.780982 \n",
       "L 78.942857 184.780982 \n",
       "L 78.942857 113.038125 \n",
       "L 7.2 113.038125 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p3690bb2957)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAYAAABw4pVUAAAF0ElEQVR4nO2cS2xUVRjHz31MZzrt9EGbVihN0YqCtSkQk0YF4wMxYDRGWbCSRRckauLKjSFudKUsjDFRE+PKhanRxBBl5WODTXyw0EAEhL6gLVXkdqbTzuM+3J3v/I/O0FZqv8X3W31n/vfec6f/Od/55tzTcfY7hxMlsMHd6BsQEDGEGWIIM8QQZoghzBBDmCGGMEMMYYYYwgwxhBliCDPEEGaIIcwQQ5ghhjBDDGGGGMIMMYQZYggzxBBmiCHMEEOYIYYwQwxhhn+rLuTmcjp20g2gOT52k+SaKG7EY5OG2reU+PT5SVwH+wjj2ud5+LlLGqjtVPA8P1gyLop9JCmv9r3a/Rv3amtugfqIfh9HTQmsEEOYIYYw4x8J22tr1bGzqR00O2+bONWQjssvopixugkKdF6AkusbeTqx9oF7pCXZDGq+ld/TKR3HOE2p2KFjq20oLm2h61Zy+HmNU9BUbtXQrLcYZulvlSrg+/CqNN+2dLeCJiOEGWIIM3yvuwtfKZd1GF6eqHmim81COx7o1/GNh7aCVujDVFfaHOk4SUegKfNQ10pZMYn+dcwffhH7SP9lxAFeJxNExnEV0Bpn6P27hWVVjyRjpDundjpXM/PQjILAuAjem4wQZoghzBBDmOGrGHPY8vB2Hc8+aNV5O6ic3dVzFaR7cz/quCuVB63JLUO7ZNSPKScErcGh/D6cmQatakwwGQfvu9XFsjfrUH5POaiZTIVYok+HNDcGMc6TxTgN7Tihz/MfYQto5vs6t7QFtJ409fnl8UdAkxHCDDGEGf7Ese3wwp5D53Q8lMbh7ClatcyHjaD9WW3W8eRyB2iug6udjR59xTWvqZRSsyX65vp5sge0jHFeGGMa2tSwBG2zz/YUaoshph6TjlRRxzmvBJqdXksJpV5PYQpdiCjdme9XKaXafepj+iD2LyOEGWIIM8QQZvi9b3wPL8ydprz9wwHMtd6dNKc0pnHJYahrRsc9mQC0fIgrszPLNE/c3nQdtG1ZanemcA5LG8urs5U20Ox8b84hCyGWr2Wj7M5b88m1MpWv9tx3tOs0tM15o8/HUv+r4k4dXyh2W+fVfropI4QZYggznPX4NaCp1x6A9ktHTkJ7X/aijk8VBkGbLFHJvBzhSsFwy+WafVaT2psjFiIs0ceXOkmrYjrdmg103O5jufzttbugnT4wUbPPS2/dr+MPn/0AtJPBLh2fG9kBmowQZoghzBBDmFF/DrGegjnmJoMwtI9eMcXDwzqefQbL51P73tXxmRI+efw6uEfH9vxilstKKbW5IdDxfBVXYueM0rY3cwO0M0GvjodacUX7idyveJ2Iyvf3ph4GTT0+q0OvuQkkp53OCydxRVtGCDPEEGaIIcxY3fcQ86lcjLtF3AzV83EJlzFWg7kL5vyJHtA+2/u+jq9GuMHsu/xOaJvLNc0ePrE0l8NHf9sN2sjAmI4/+mI/aNuOj0Hb76P5Zvz5XtB+Ova2jp978iholQ5ayvG/+Rk0GSHMEEOYsS5LJzfv1Sin7f279U7bPaDjS0ewlL3jPiwfR+/+VMcf53HJ45dFKqeni7h/+WDXWR0faj4L2gt9e1d8r3Mv0/LRbU9PofjYlZrnyQhhhhjCDDGEGRszh9RjjfOLzfyLlMODQVzmOfHoJzqeC7F8XoyoXB6dwJK486kLK+7f/Bpw8XW8Tv8rY/bhdN6KexD+F8QQZvBLWXVwUrRfN6lW6hy5cq68ik833xmhp3tv9g/ah687MkKYIYYwQwxhxsbPIfX+N88qe82f6EiiqP6xa51v6qxorwYnTRvwkorVf51yXkYIM8QQZtyyXwNaM6v4Nr6ajRVrLov/Q5qC/svlmx/0L8gIYYYYwgwxhBliCDPEEGaIIcwQQ5ghhjBDDGGGGMIMMYQZYggzxBBmiCHMEEOYIYYwQwxhhhjCDDGEGWIIM8QQZoghzBBDmCGGMEMMYYYYwgwxhBliCDP+Bv5rdWloFbDlAAAAAElFTkSuQmCC\" id=\"image215762527c\" transform=\"scale(1 -1) translate(0 -72)\" x=\"7.2\" y=\"-112.780982\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_33\">\n",
       "    <path d=\"M 7.2 184.780982 \n",
       "L 7.2 113.038125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_34\">\n",
       "    <path d=\"M 78.942857 184.780982 \n",
       "L 78.942857 113.038125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_35\">\n",
       "    <path d=\"M 7.2 184.780982 \n",
       "L 78.942857 184.780982 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_36\">\n",
       "    <path d=\"M 7.2 113.038125 \n",
       "L 78.942857 113.038125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_7\">\n",
       "    <!-- sneaker -->\n",
       "    <g transform=\"translate(19.359241 107.038125) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-73\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"52.099609\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"115.478516\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"177.001953\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6b\" x=\"238.28125\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"292.566406\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"354.089844\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_8\">\n",
       "   <g id=\"patch_37\">\n",
       "    <path d=\"M 93.291429 184.780982 \n",
       "L 165.034286 184.780982 \n",
       "L 165.034286 113.038125 \n",
       "L 93.291429 113.038125 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#pb905ffb1bf)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAYAAABw4pVUAAAJX0lEQVR4nO1dXWwc1RW+M7OzXrze2LHj/BgcRKEES+EJ4UJEqyKBhKjUUIX2pVKlNvwU9YFKRVWjwgMC8dJWtFJoJVpVgpcC4hGhBJGXFoUIQmKahlSOqBPSGJzEZoPj9e7Ozkzf7j3fseZ618HoVDrf07k+8+c9c88597vn3gnuCR7MTbcIAit+9vidoKosuMsMnG+DrnToA7xMXLZynuCxkhCUStDOOx1oz+91v8Ffn3oedPWsYuVf7fsp6GqvHim8Z9jzUyrWFWoQYVCDCENp9UMIchcn/vz4H0A12Rdb+UdnvwW6uUN4mbB6jZXTutwYYgL/+9ocdTF1a5SCbixasnLew2uvPUQY1CDC0JPLiia+buV6ehJ0M8nnVp6auxZ028wX0E7rl7u7YRhBM4giIuO7lOee7D0r1uUpuhqTuXbeSbyP17x12coDQQy6U+TUwYfP4T3/VnxN7SHCoAYRBjWIMAQ+6iTashnabx5/y8pTrRbo4iCz8k0xhqbvXnv7VT2kVOydnrHyrsp50B1uuji6p/o56CZe/pmVb9j3Lui0hwiDGkQYvGnv5ZcGCnXn00Foj4RuZNoXRPzwLwVhterk4Y1MGWCbprosJc6bTSunl+bX/Dw/GHDp+8k2/s8j0RUrz2fLoLt+8r+F19QeIgxqEGFQgwiDN4Ywr2xmEucXk7w4vqyG6T9NWnn/vS+D7mulBStPlPtBd2jZ+emRsOG9R5u8axmjW78gs3l3VZZA18rdrOCzF+4C3d9f+Aa7y5SVUvZrLWV9Vt4cVUH32cFxK48ZpFW0hwiDGkQYvC5rOUH1DbFzU29cGQHdeP8CaWEKuPATLIg4/J3fWHkwLINupuO6PmcDIuMmtuazfqbD1Ja6EK6rhI6Knekg2xsH7tjfbTsGuh8/gq4HzjMZtCtBMVO8/TWX9naYTnuIMKhBhEENIgzeGNI5tAn/cJsTaxHSAcMhLVbAuPD7J1+A9rG2u26S4yPUQnfd1FMdUA0xvtA00xhjIsI+hwH697JxcaPOzquT2HSseQ3odo8ch/al1KXMtbD7esPOmU8KddpDhEENIgxqEGHwxpDrXj+Lf/ilE4cipC6GQmfb91qYg9ezGjvWnXu+gzQ6jQUZe1+GCaU9xGJInY1LaJxoZlgRknkK4BZTFzdGS1gtw+NUk9D65QCpk3LAqlm6hPYQYVCDCIPXZc3dt71QFzKqICZuoMK6K09tq4RWoDNrxqBb4PdoEF01wJpgTlXQVBeTcEQzjwt1/LkbzGUtZu5/Hi/hu81T7W6hPUQY1CDCoAYRBm8MyYrd6wrfn+TOZ2Y50u8fLWPx9VjNFY7FnnjD6RFKqSfsHj66m6fPbXIujyGUmh+NFkE3xGYpF8m5zRxjGsY4XxRDaA8RBjWIMHhd1ta35/APTzmxEuBcVz2j7CraeVOMXZ+mj0MhssYLJF2M2T1MXvy4fFaQwr/KA0Hd0liEbihmo/G3G9dZeWuExQr95NlbOS8XKYb2EGFQgwiDGkQYvDEkPf0faH/acanuKKunPtdxbOt4CdPDMosFNO2MGcWAumLGtM0qW3gaTM9dOWPoUM/wvGHCYl/M8OfZEeOxlA1eyvDdjkj1yhtLWKHjg/YQYVCDCENPy6JfXdxp5YcG/w26qdQV0VXZqPl7AzjRdbTljuU1sb70dT3A636HQudep1q4pG88ugTtyLj0vcVcZptcd88ATnS9SNNntnZFe4gwqEGEQQ0iDD3FkJf+eL+Vf/7rM6DjzCzFh20sOJsn8Wa1dR7rAZpaU3bXGGMo97uQ4hqYxfwCtLcQxvssK9bYWXZrF7/9r++Dri8/U/hs2kOEQQ0iDGoQYegphiSeZYV0pm+Q+eUaI8BnE+dv2553go8RaPG1j1ZZDXQGscbo/wYZFvCql4UUZxdvLbv26QTHIUOh+z0WWzhjiLUrCO0hwqAGEYaeXBYhME2S87V5jnKosW0uLnt2dONuiboQXoBA77GiXtcUuzdfnS2naubpbCarX+brGlu5e1ae9i9k7lk37N9QeH8O7SHCoAYRBjWIMPQUQzYfdX7ySsbXkDufnjBKmceUrSW3rdF8hmu/aYFZk8UX8Pe8mJmFqchT7EzT2TajzcMeiq/nUvesoxHeb3vJjRHKB48WXnPlsylEQQ0iDD25rDBx3bKZYxelhQTnUhyL7oixyIHOEtIlZMYYUym5UT13JzTt5e6DzzzSdDplI26aIvPROC2W4PXCjRz/rypxxUmGqfWBhm88XgztIcKgBhEGNYgw9BZD/uG2lnifVWTcUr5o5dMJFoZN9jWhfbHjqAROT1C/nbKibcrwcsqDx5sIirbRv9P4ws+jlAunQxY7GO9OtN3/sSPGDwz0e2ZQfdAeIgxqEGHo7ZNHBHS0bYwxKVkD4VteZowxqWeCiLoi7jLAZQVXUVBHMmR/uow6voyPurttETLB3zzwsJVvNu93/WjaQ4RBDSIMahBhWHMM2ffxHmjvv+kVK9dTZHDTvA5tX4yhFAx/W8qmmMHl/r5brCjuDigTzJZMs+e+kLpdjuazOug2Hvf8tFps/f8DNYgwqEGEwb8Zv+fz1aV7cGfNiVmXhzdyXNgynfD9mx04rVEFip1veeT8bdbD2m8ffAuEVtDvbHsmOhbjG+5vOzBrZf7fByUXm/jny7WHCIMaRBi8Lou6qNVw+5OPWfnIM7hx8oFlLBSjdEmNuYXE8440CVXBl0Fz1+Or/aXH9vHdiMj9E1aMR787Yowxd1Qcw33nE78A3YaZI4X3526KQnuIMKhBhEENIgzeT6+uPLp4yE8x8QGGpue2HIb2O02XIvIZQ0p/8y2gKD2y2tZJsyndNQ7jDY1bc2nxopdaiDOdt/XhOo+7T+62cvletuk0BXs232+nPUQY1CDC0JvLogjZdkBZcZq560N0L3s3vmflYfYNqk9Jvey5DqbLo5H7XseJ1hjoTjWxfffAKSuPlXBHu9mOY2m3sFnA6wk78U/2OdXHTvwQ2pt34/YiAPr7eH6bFad1faTiK4EaRBjUIMKw9hjC0YPPjG6+0crTj46C7uCDv7XyjbFnHfZVoJW7tLeRIXWz6y9PWHn705iue9FDTPVeZk1nKdYNahBh+PJcFh+NUnhGpj4sPzAJ7YGP3A476fTHXV8n3HkLtC/scjtJbHrx3TU923pBe4gwqEGEQQ0iDP8DGCDhyIHg3H4AAAAASUVORK5CYII=\" id=\"image61e14e3aac\" transform=\"scale(1 -1) translate(0 -72)\" x=\"93.291429\" y=\"-112.780982\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_38\">\n",
       "    <path d=\"M 93.291429 184.780982 \n",
       "L 93.291429 113.038125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_39\">\n",
       "    <path d=\"M 165.034286 184.780982 \n",
       "L 165.034286 113.038125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_40\">\n",
       "    <path d=\"M 93.291429 184.780982 \n",
       "L 165.034286 184.780982 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_41\">\n",
       "    <path d=\"M 93.291429 113.038125 \n",
       "L 165.034286 113.038125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_8\">\n",
       "    <!-- pullover -->\n",
       "    <g transform=\"translate(104.836607 107.038125) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"63.476562\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"126.855469\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"154.638672\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"182.421875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-76\" x=\"243.603516\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"302.783203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"364.306641\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_9\">\n",
       "   <g id=\"patch_42\">\n",
       "    <path d=\"M 179.382857 184.780982 \n",
       "L 251.125714 184.780982 \n",
       "L 251.125714 113.038125 \n",
       "L 179.382857 113.038125 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p9dc0d1b11c)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image7e0beb4a49\" transform=\"scale(1 -1) translate(0 -72)\" x=\"179.382857\" y=\"-112.780982\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_43\">\n",
       "    <path d=\"M 179.382857 184.780982 \n",
       "L 179.382857 113.038125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_44\">\n",
       "    <path d=\"M 251.125714 184.780982 \n",
       "L 251.125714 113.038125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_45\">\n",
       "    <path d=\"M 179.382857 184.780982 \n",
       "L 251.125714 184.780982 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_46\">\n",
       "    <path d=\"M 179.382857 113.038125 \n",
       "L 251.125714 113.038125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_9\">\n",
       "    <!-- sandal -->\n",
       "    <g transform=\"translate(195.496473 107.038125) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-73\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"52.099609\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"113.378906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" x=\"176.757812\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"240.234375\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"301.513672\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_10\">\n",
       "   <g id=\"patch_47\">\n",
       "    <path d=\"M 265.474286 184.780982 \n",
       "L 337.217143 184.780982 \n",
       "L 337.217143 113.038125 \n",
       "L 265.474286 113.038125 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#pfa1bc279dc)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"imageaf29f5f235\" transform=\"scale(1 -1) translate(0 -72)\" x=\"265.474286\" y=\"-112.780982\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_48\">\n",
       "    <path d=\"M 265.474286 184.780982 \n",
       "L 265.474286 113.038125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_49\">\n",
       "    <path d=\"M 337.217143 184.780982 \n",
       "L 337.217143 113.038125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_50\">\n",
       "    <path d=\"M 265.474286 184.780982 \n",
       "L 337.217143 184.780982 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_51\">\n",
       "    <path d=\"M 265.474286 113.038125 \n",
       "L 337.217143 113.038125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_10\">\n",
       "    <!-- sandal -->\n",
       "    <g transform=\"translate(281.587902 107.038125) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-73\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"52.099609\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"113.378906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" x=\"176.757812\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"240.234375\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"301.513672\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_11\">\n",
       "   <g id=\"patch_52\">\n",
       "    <path d=\"M 351.565714 184.780982 \n",
       "L 423.308571 184.780982 \n",
       "L 423.308571 113.038125 \n",
       "L 351.565714 113.038125 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p716a5c55bd)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image4e628a8ab0\" transform=\"scale(1 -1) translate(0 -72)\" x=\"351.565714\" y=\"-112.780982\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_53\">\n",
       "    <path d=\"M 351.565714 184.780982 \n",
       "L 351.565714 113.038125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_54\">\n",
       "    <path d=\"M 423.308571 184.780982 \n",
       "L 423.308571 113.038125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_55\">\n",
       "    <path d=\"M 351.565714 184.780982 \n",
       "L 423.308571 184.780982 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_56\">\n",
       "    <path d=\"M 351.565714 113.038125 \n",
       "L 423.308571 113.038125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_11\">\n",
       "    <!-- t-shirt -->\n",
       "    <g transform=\"translate(369.506518 107.038125) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2d\" x=\"39.208984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"75.292969\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-68\" x=\"127.392578\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"190.771484\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"218.554688\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"259.667969\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_12\">\n",
       "   <g id=\"patch_57\">\n",
       "    <path d=\"M 437.657143 184.780982 \n",
       "L 509.4 184.780982 \n",
       "L 509.4 113.038125 \n",
       "L 437.657143 113.038125 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#pc1a8f19eb0)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image905b4a53ef\" transform=\"scale(1 -1) translate(0 -72)\" x=\"437.657143\" y=\"-112.780982\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_58\">\n",
       "    <path d=\"M 437.657143 184.780982 \n",
       "L 437.657143 113.038125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_59\">\n",
       "    <path d=\"M 509.4 184.780982 \n",
       "L 509.4 113.038125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_60\">\n",
       "    <path d=\"M 437.657143 184.780982 \n",
       "L 509.4 184.780982 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_61\">\n",
       "    <path d=\"M 437.657143 113.038125 \n",
       "L 509.4 113.038125 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_12\">\n",
       "    <!-- ankle boot -->\n",
       "    <g transform=\"translate(441.805446 107.038125) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-61\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"61.279297\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6b\" x=\"124.658203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"182.568359\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"210.351562\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"271.875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-62\" x=\"303.662109\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"367.138672\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"428.320312\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"489.501953\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p16b28cdef4\">\n",
       "   <rect x=\"7.2\" y=\"22.318125\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p20099da8f2\">\n",
       "   <rect x=\"93.291429\" y=\"22.318125\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"pd7a319506f\">\n",
       "   <rect x=\"179.382857\" y=\"22.318125\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p5b16338dae\">\n",
       "   <rect x=\"265.474286\" y=\"22.318125\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"pbb2dee9e5b\">\n",
       "   <rect x=\"351.565714\" y=\"22.318125\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"pbc00dfce37\">\n",
       "   <rect x=\"437.657143\" y=\"22.318125\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p3690bb2957\">\n",
       "   <rect x=\"7.2\" y=\"113.038125\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"pb905ffb1bf\">\n",
       "   <rect x=\"93.291429\" y=\"113.038125\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p9dc0d1b11c\">\n",
       "   <rect x=\"179.382857\" y=\"113.038125\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"pfa1bc279dc\">\n",
       "   <rect x=\"265.474286\" y=\"113.038125\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p716a5c55bd\">\n",
       "   <rect x=\"351.565714\" y=\"113.038125\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"pc1a8f19eb0\">\n",
       "   <rect x=\"437.657143\" y=\"113.038125\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 900x300 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 12\n",
    "X, y = next(iter(data.DataLoader(mnist_train, batch_size)))\n",
    "show_images(X.reshape(12, 28, 28), 2, 6, titles=get_fashion_mnist_labels(y));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5.2 读取小批量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了在读取训练集和测试集时更容易，我们使用内置的数据迭代器，而不是从零开始创建\n",
    "batch_size = 256\n",
    "\n",
    "def get_dataloader_workers(): #@save\n",
    "    '''使用4个进程来读取数据'''\n",
    "    return 4\n",
    "\n",
    "train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True, \n",
    "                             num_workers=get_dataloader_workers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16 sec'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据所需时间\n",
    "timer = d2l.Timer()\n",
    "for X, y in train_iter:\n",
    "    continue\n",
    "f'{timer.stop():.2f} sec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.5.3 整合所有组件\n",
    "# 现在定义load_data_fashion_mnist函数，用于获取和读取Fashion-MNIST数据集。 \n",
    "# 这个函数返回训练集和验证集的数据迭代器。 \n",
    "# 此外，这个函数还接受一个可选参数resize，用来将图像大小调整为另一种形状。\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None): #@save\n",
    "    '''下载fashion mnist数据集并加载到内存'''\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    \n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root='./data', train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root='./data', train=False, transform=trans, download=True)\n",
    "    \n",
    "    return (data.DataLoader(mnist_train, batch_size, shuffle=True, \n",
    "                           num_workers=get_dataloader_workers()), \n",
    "            data.DataLoader(mnist_train, batch_size, shuffle=True, \n",
    "                            num_workers=get_dataloader_workers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 64, 64]) torch.float32 torch.Size([32]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "train_iter, test_iter = load_data_fashion_mnist(32, resize=64)\n",
    "for X, y in train_iter:\n",
    "    print(X.shape, X.dtype, y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 小结\n",
    "# Fashion-MNIST是一个服装分类数据集，由10个类别的图像组成。我们将在后续章节中使用此数据集来评估各种分类算法。\n",
    "# 数据迭代器是获得更高性能的关键组件。依靠实现良好的数据迭代器，利用高性能计算来避免减慢训练过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 softmax回归从零开始实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.1 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0015, -0.0173,  0.0079,  ..., -0.0010, -0.0145,  0.0068],\n",
       "         [-0.0013,  0.0003,  0.0045,  ..., -0.0146, -0.0022,  0.0127],\n",
       "         [ 0.0130, -0.0028,  0.0010,  ...,  0.0115,  0.0104,  0.0090],\n",
       "         ...,\n",
       "         [ 0.0174,  0.0138,  0.0052,  ...,  0.0068,  0.0040,  0.0182],\n",
       "         [-0.0054, -0.0092, -0.0034,  ..., -0.0053,  0.0004, -0.0002],\n",
       "         [-0.0219, -0.0087,  0.0073,  ..., -0.0239,  0.0109,  0.0062]],\n",
       "        requires_grad=True),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 原始数据集中的每个样本都是28*28的图像。本节将展平每个图像，把它们看作长度为784的向量\n",
    "num_inputs = 784\n",
    "num_outputs = 10 # W 784*10\n",
    "\n",
    "W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)\n",
    "b = torch.zeros(10, requires_grad=True)\n",
    "W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.2 定义softmax操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 7., 9.]]),\n",
       " tensor([[ 6.],\n",
       "         [15.]]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "X.sum(0, keepdim=True), X.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现softmax由三个步骤组成：\n",
    "# 对每个项求幂（使用exp）；\n",
    "# 对每一行求和（小批量中每个样本是一行），得到每个样本的规范化常数；\n",
    "# 将每一行除以其规范化常数，确保结果的和为1。\n",
    "\n",
    "def softmax(X): # X n*10\n",
    "    X_exp = torch.exp(X)\n",
    "    partition = X_exp.sum(1, keepdim=True)\n",
    "    return X_exp / partition # 广播机制 n*10 / n*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1437, 0.2325, 0.2996, 0.1434, 0.1807],\n",
       "         [0.1148, 0.1120, 0.4356, 0.2167, 0.1209]]),\n",
       " tensor([1.0000, 1.0000]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 虽然这在数学上看起来是正确的，但在代码实现中有点草率。 矩阵中的非常大或非常小的元素可能造成数值上溢或下溢\n",
    "X = torch.normal(0, 1, (2, 5))\n",
    "x_prob = softmax(X)\n",
    "x_prob, x_prob.sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.3 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    return softmax(torch.matmul(X.reshape(-1, W.shape[0]), W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.4 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4000, 0.5000])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 交叉熵采用真实标签的预测概率的负对数似然\n",
    "y = torch.tensor([2, 2]) # 标签\n",
    "y_hat = torch.tensor([[0.3, 0.3, 0.4], [0.1, 0.4, 0.5]])\n",
    "# tensor 可以按照索引取值\n",
    "y_hat[[0, 1], y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9163, 0.6931])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 损失函数(Loss Function )是定义在单个样本上的,算的是一个样本的误差。\n",
    "# 代价函数(Cost Function )是定义在整个训练集上的,是所有样本误差的平均,也就是损失函数的平均。\n",
    "def cross_entropy(y_hat, y):\n",
    "    return -torch.log(y_hat[range(len(y_hat)), y])\n",
    "\n",
    "cross_entropy(y_hat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.5 分类精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 那么假定第二个维度存储每个类的预测分数。\n",
    "# 使用argmax获得每行中最大元素的索引来获得预测类别。 然后我们将预测类别与真实y元素进行比较。\n",
    "\n",
    "def accuracy(y_hat, y): #@save\n",
    "    '''计算精确度'''\n",
    "    # 样本大于1且为多分类问题\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    # 可以用.to()函数进行转换\n",
    "    cmp = y_hat.to(y.dtype) == y\n",
    "    return float(cmp.to(y.dtype).sum()) #float后标量不是tenser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以用.to()函数进行转换\n",
    "result = torch.tensor([True, False]).to(torch.float32)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_hat, y) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个实用程序类Accumulator，用于对多个变量进行累加。 \n",
    "# evaluate_accuracy函数中， 在Accumulator实例中创建了2个变量， \n",
    "# 分别用于存储正确预测的数量和预测的总数量。 当我们遍历数据集时，两者都将随着时间的推移而累加。\n",
    "\n",
    "# 参数带星号表示支持可变不定数量的参数，这种方法叫参数收集\n",
    "# 带一个星号的参数收集模式：\n",
    "# 这种模式是在函数定义时在某个形参前面加一个星号，调用时按位置匹配不带星号的形参和实参，\n",
    "# 多余的实参都将作为一个元组的元素保存到星号对应的形参中。\n",
    "\n",
    "class Accumulator: #@save\n",
    "    '''在n个变量上累加'''\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "        \n",
    "    def add(self, *args):\n",
    "        self.data = [k + float(v) for k, v in zip(self.data, args)]\n",
    "        \n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 来判断一个对象是否是一个已知的类型\n",
    "# eval（）时，pytorch会自动把BN和DropOut固定住，不会取平均，而是用训练好的值。\n",
    "\n",
    "def evaluate_accuracy(net, data_iter): #@save\n",
    "    '''评估指定数据集上模型的精度'''\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval() # 将模型设置为评估模式\n",
    "    metric = Accumulator(2) # 正确， 总数\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluate_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[78], line 10\u001b[0m, in \u001b[0;36mevaluate_accuracy\u001b[1;34m(net, data_iter)\u001b[0m\n\u001b[0;32m      8\u001b[0m metric \u001b[38;5;241m=\u001b[39m Accumulator(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# 正确， 总数\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m data_iter:\n\u001b[0;32m     11\u001b[0m         metric\u001b[38;5;241m.\u001b[39madd(accuracy(net(X), y), y\u001b[38;5;241m.\u001b[39mnumel())\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metric[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m metric[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1316\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1278\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1282\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1283\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1284\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1108\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1120\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1123\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\multiprocessing\\connection.py:330\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    328\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\multiprocessing\\connection.py:879\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    876\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    877\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 879\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\d2l\\lib\\multiprocessing\\connection.py:811\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    809\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 811\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate_accuracy(net, test_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.6 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化算法sgd\n",
    "lr = 0.1\n",
    "\n",
    "def updater(batch_size):\n",
    "    return d2l.sgd([W, b], lr, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个epoch的训练过程\n",
    "\n",
    "def train_epoch_ch3(train_iter, net, loss, updater): #@save\n",
    "    '''训练一个epoch'''\n",
    "    # 采用pytorch框架的话切换训练模式\n",
    "    # 模型在默认情况下是train模型，所以model.training为True,模型在eval情况下，model.training为False\n",
    "    metric = Accumulator(3) # loss sum, 正确sum, 全体sum\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    for X, y in train_iter:\n",
    "        # 计算梯度更新参数\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y) # 自己定义的交叉熵loss，返回每个样本的交叉熵\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            # 使用pytorch自带优化器\n",
    "            updater.zero_grad()\n",
    "            l.mean().backward() # 交叉熵均值反向穿播\n",
    "            updater.step() # torch优化器更新梯度默认不会除以batchsize\n",
    "        else:\n",
    "            # 使用自定义优化器\n",
    "            l.sum().backward()\n",
    "            updater(X.shape[0]) # 自带计算平均梯度(除以batch_size)和梯度清零\n",
    "        metric.add(l.sum(), accuracy(net(X), y), y.numel())\n",
    "    # 返回训练损失和训练精度\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_epoch_ch3(train_iter, net, cross_entropy, updater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个在动画中绘制数据的实用程序类Animator\n",
    "\n",
    "class Animator:  #@save\n",
    "    \"\"\"在动画中绘制数据\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        # 增量地绘制多条线\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        d2l.use_svg_display()\n",
    "        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # 使用lambda函数捕获参数\n",
    "        self.config_axes = lambda: d2l.set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # 向图表中添加多个数据点\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现一个训练函数， 它会在train_iter访问到的训练数据集上训练一个模型net。 \n",
    "# 该训练函数将会运行多个迭代周期（由num_epochs指定）。 \n",
    "# 在每个迭代周期结束时，利用test_iter访问到的测试数据集对模型进行评估。 \n",
    "\n",
    "def train_ch3(train_iter, test_iter, net, loss, updater, num_epochs): #@save\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9], \n",
    "                       legend=['train_loss', 'train_acc', 'test_acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        # 用accumulator3实现训练过程的train loss和train_acc\n",
    "        train_metrics = train_epoch_ch3(train_iter, net, loss, updater) \n",
    "        test_acc = evaluate_accuracy(net, test_iter) # 用accumulator2实现固定网络的_iter loss\n",
    "        animator.add(epoch+1, train_metrics+(test_acc,))\n",
    "    train_loss, train_acc = train_metrics\n",
    "    print(f'epoch {epoch+1}: train_loss {train_loss:.5f} train_acc:{train_acc:.5f} test_acc{test_acc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type((3.0,)), type((3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "train_ch3(train_iter, test_iter, net, cross_entropy, updater, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.7 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 给定一系列图像，将比较它们的实际标签（文本输出的第一行）和模型预测（文本输出的第二行）\n",
    "\n",
    "# net是一个函数，但是W和b已经训练过\n",
    "def predict_ch3(test_iter, net, n=6): #@save\n",
    "    for X, y in test_iter:\n",
    "        break\n",
    "    # for 循环外 X,y变量依然存在\n",
    "    trues = d2l.get_fashion_mnist_labels(y)\n",
    "    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1))\n",
    "    titles = [true + '\\n' + pred for true, pred in zip(trues, preds)]\n",
    "    d2l.show_images(\n",
    "        X[-7: -1].reshape(n, 28, 28), 1, n, titles=titles[0: n])\n",
    "predict_ch3(test_iter, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    c = 1\n",
    "    break\n",
    "print(i)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 小结\n",
    "# 借助softmax回归，我们可以训练多分类的模型。\n",
    "# 训练softmax回归循环模型与训练线性回归模型非常相似：先读取数据，再定义模型和损失函数，然后使用优化算法训练模型。\n",
    "# 大多数常见的深度学习模型都有类似的训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.7 softmax回归简洁实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7.1 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7.2 定义模型、初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax回归的输出层是一个全连接层。只需在Sequential中添加一个带有10个输出的全连接层。 \n",
    "# 这里Sequential并不是必要的， 但它是实现深度模型的基础。 仍然以均值0和标准差0.01随机初始化权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch不会隐式地调整输入的形状。因此，\n",
    "# 我们在线性层前定义了展平层（flatten），来调整网络输入的形状，适用于图像输入\n",
    "\n",
    "net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net, type(net[0]), type(net[1]), net[1].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "\n",
    "# 每一个层作用于函数\n",
    "net.apply(init_weights)\n",
    "net[1].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7.3 重新审视Softmax的实现、交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算了模型的输出，然后将此输出送入交叉熵损失。从数学上讲，这是一件完全合理的事情。\n",
    "# 从计算角度来看，指数可能会造成数值稳定性问题。指数操作可能导致上溢\n",
    "# 解决这个问题的一个技巧是：在继续softmax计算之前，先从所有ok中减去max(ok)\n",
    "# 按常数进行的移动不会改变softmax的返回值\n",
    "# 但是这可能会造成许多y估计趋向于0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尽管要softmax计算指数函数，但最终在计算交叉熵损失时会取它们的对数。 \n",
    "# 通过将softmax和交叉熵结合在一起，可以避免反向传播过程中可能会困扰我们的数值稳定性问题。\n",
    "# 没有像softmax逐步实现将softmax概率传递到损失函数中，而是在交叉熵损失函数中传递未规范化的预测，\n",
    "# 并同时计算softmax及其对数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduction：用来指定损失结果返回的是mean、sum还是none\n",
    "# 当 reduction='none' 时，函数会输出一个形状为 (batch_size, num_classes) 的矩阵，表示每个样本的每个类别的损失。\n",
    "# 当 reduction='sum' 时，函数会对矩阵求和，输出一个标量，表示所有样本的损失之和。\n",
    "loss = nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7.4 优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7.5 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "train_ch3(train_iter, test_iter, net, loss, trainer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 小结\n",
    "# 使用深度学习框架的高级API，我们可以更简洁地实现softmax回归。\n",
    "# 从计算的角度来看，实现softmax回归比较复杂。\n",
    "# 在许多情况下，深度学习框架在这些著名的技巧之外采取了额外的预防措施，来确保数值的稳定性。\n",
    "# 这避免了在实践中从零开始编写模型时可能遇到的陷阱。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
